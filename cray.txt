Overview: We are using the sum of archived human expression data to
create a collection of statistical classifiers covering <as many
phenotypes as we can think of>.  This set of classifiers would
provide a "molecular signature" for each of the phenotypes used in
training, such that any new expression dataset could then be
identified 




Background: Description of classifiers.  A classifier is a statistical
test that, once trained, provides a yes/no classification to a new
input data set with minimal computation resources required.  They can
be used to to indicate if a given sample exhibits characteristics
of a particular phenotype or molecular state.

Our procedure is to download all non-redundant human expression data
from public repositories such as the Gene Omnibus Expression,
OncoMine, ArrayExpress, etc, along with all metadata associated with
each dataset.  Typical metadata includes textual information such as
experiment titles and descriptions, pubmed IDs (from which abstracts
of reporting journal articles may be obtained), among other data.

This textual data is used to produce overlapping groups of related
samples based on simple keyword associations.  These samples groups
are then clustered based on gene expression values until distinct
phenotype groups are determined.  

Each group is then labeled with it's corresponding phenotype and used
as a training set in the creating of a classifier.  When new
expression data becomes available via the public repositories or from
other sources, it is run against the existing classifiers to determine
it's properties.  It can also be used to improve the accuracy of
classifiers as needed.

A provenance history of each sample and each classifier is also kept
to that the long term characteristics of the classifiers can be
tracked and global trends in the expression data can be determined.

